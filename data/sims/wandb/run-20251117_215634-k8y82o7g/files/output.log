Generating dataset with teacher...
train	ep 00000	it 000	loss 1.118e+01	ex 8000	time 0.00s
train	ep 00100	it 000	loss 3.828e-02	ex 8000	time 4.92s
train	ep 00200	it 000	loss 5.001e-03	ex 8000	time 7.88s
train	ep 00300	it 000	loss 2.059e-03	ex 8000	time 7.39s
train	ep 00400	it 000	loss 9.048e-04	ex 8000	time 8.06s
train	ep 00500	it 000	loss 4.369e-04	ex 8000	time 8.05s
train	ep 00600	it 000	loss 2.079e-04	ex 8000	time 7.61s
train	ep 00700	it 000	loss 9.965e-05	ex 8000	time 6.67s
train	ep 00800	it 000	loss 5.019e-05	ex 8000	time 6.34s
train	ep 00900	it 000	loss 2.866e-05	ex 8000	time 8.18s
train	ep 01000	it 000	loss 1.590e-05	ex 8000	time 6.42s
train	ep 01100	it 000	loss 1.092e-05	ex 8000	time 7.10s
train	ep 01200	it 000	loss 3.960e-06	ex 8000	time 6.58s
train	ep 01300	it 000	loss 2.263e-06	ex 8000	time 7.69s
train	ep 01400	it 000	loss 8.592e-06	ex 8000	time 6.42s
train	ep 01500	it 000	loss 7.769e-06	ex 8000	time 7.59s
train	ep 01600	it 000	loss 1.087e-05	ex 8000	time 7.36s
train	ep 01700	it 000	loss 2.337e-06	ex 8000	time 6.74s
train	ep 01800	it 000	loss 1.537e-06	ex 8000	time 7.46s
train	ep 01900	it 000	loss 4.099e-06	ex 8000	time 6.82s
train	ep 02000	it 000	loss 1.106e-06	ex 8000	time 6.80s
train	ep 02100	it 000	loss 1.116e-05	ex 8000	time 6.55s
train	ep 02200	it 000	loss 2.170e-06	ex 8000	time 6.07s
train	ep 02300	it 000	loss 9.694e-07	ex 8000	time 7.69s
train	ep 02400	it 000	loss 2.075e-05	ex 8000	time 6.36s
train	ep 02500	it 000	loss 2.822e-06	ex 8000	time 7.46s
train	ep 02600	it 000	loss 2.353e-06	ex 8000	time 8.01s
train	ep 02700	it 000	loss 1.510e-06	ex 8000	time 7.66s
train	ep 02800	it 000	loss 8.291e-07	ex 8000	time 6.67s
train	ep 02900	it 000	loss 2.092e-06	ex 8000	time 6.38s
train	ep 03000	it 000	loss 3.423e-06	ex 8000	time 6.01s
train	ep 03100	it 000	loss 2.191e-06	ex 8000	time 6.17s
train	ep 03200	it 000	loss 1.209e-06	ex 8000	time 7.22s
train	ep 03300	it 000	loss 1.249e-05	ex 8000	time 6.49s
train	ep 03400	it 000	loss 1.576e-06	ex 8000	time 6.33s
train	ep 03500	it 000	loss 1.743e-06	ex 8000	time 6.49s
train	ep 03600	it 000	loss 7.562e-07	ex 8000	time 6.73s
train	ep 03700	it 000	loss 2.093e-06	ex 8000	time 6.27s
train	ep 03800	it 000	loss 2.515e-06	ex 8000	time 7.08s
train	ep 03900	it 000	loss 7.392e-06	ex 8000	time 6.49s
train	ep 04000	it 000	loss 9.039e-06	ex 8000	time 7.41s
train	ep 04100	it 000	loss 3.149e-06	ex 8000	time 6.55s
train	ep 04200	it 000	loss 5.247e-06	ex 8000	time 6.24s
train	ep 04300	it 000	loss 2.812e-06	ex 8000	time 6.77s
train	ep 04400	it 000	loss 1.053e-05	ex 8000	time 5.89s
train	ep 04500	it 000	loss 1.127e-05	ex 8000	time 6.47s
train	ep 04600	it 000	loss 2.661e-06	ex 8000	time 5.66s
train	ep 04700	it 000	loss 2.557e-06	ex 8000	time 6.97s
train	ep 04800	it 000	loss 9.058e-06	ex 8000	time 6.28s
train	ep 04900	it 000	loss 3.282e-07	ex 8000	time 6.51s
train	ep 05000	it 000	loss 1.180e-05	ex 8000	time 6.11s
train	ep 05100	it 000	loss 3.307e-06	ex 8000	time 6.20s
train	ep 05200	it 000	loss 1.359e-06	ex 8000	time 5.78s
train	ep 05300	it 000	loss 1.684e-05	ex 8000	time 6.94s
train	ep 05400	it 000	loss 1.202e-06	ex 8000	time 5.23s
train	ep 05500	it 000	loss 7.197e-06	ex 8000	time 7.24s
train	ep 05600	it 000	loss 1.831e-06	ex 8000	time 6.46s
train	ep 05700	it 000	loss 6.804e-06	ex 8000	time 7.45s
train	ep 05800	it 000	loss 1.717e-06	ex 8000	time 8.23s
train	ep 05900	it 000	loss 7.573e-06	ex 8000	time 7.01s
train	ep 06000	it 000	loss 1.046e-06	ex 8000	time 6.13s
train	ep 06100	it 000	loss 6.315e-06	ex 8000	time 6.31s
train	ep 06200	it 000	loss 3.525e-06	ex 8000	time 7.74s
train	ep 06300	it 000	loss 1.091e-05	ex 8000	time 5.82s
train	ep 06400	it 000	loss 3.534e-06	ex 8000	time 6.24s
train	ep 06500	it 000	loss 7.443e-06	ex 8000	time 5.96s
train	ep 06600	it 000	loss 2.508e-06	ex 8000	time 5.94s
train	ep 06700	it 000	loss 9.600e-06	ex 8000	time 6.05s
train	ep 06800	it 000	loss 5.478e-06	ex 8000	time 7.26s
train	ep 06900	it 000	loss 1.662e-05	ex 8000	time 6.44s
train	ep 07000	it 000	loss 5.264e-06	ex 8000	time 5.93s
train	ep 07100	it 000	loss 7.353e-06	ex 8000	time 6.81s
train	ep 07200	it 000	loss 2.548e-06	ex 8000	time 7.62s
train	ep 07300	it 000	loss 1.255e-06	ex 8000	time 7.82s
train	ep 07400	it 000	loss 1.284e-05	ex 8000	time 6.62s
train	ep 07500	it 000	loss 2.109e-06	ex 8000	time 7.41s
train	ep 07600	it 000	loss 3.482e-07	ex 8000	time 7.32s
train	ep 07700	it 000	loss 2.036e-06	ex 8000	time 8.38s
train	ep 07800	it 000	loss 1.561e-06	ex 8000	time 7.19s
train	ep 07900	it 000	loss 4.636e-07	ex 8000	time 5.98s
train	ep 08000	it 000	loss 5.678e-06	ex 8000	time 7.21s
train	ep 08100	it 000	loss 4.822e-06	ex 8000	time 7.56s
train	ep 08200	it 000	loss 2.003e-06	ex 8000	time 7.44s
train	ep 08300	it 000	loss 4.983e-06	ex 8000	time 7.50s
train	ep 08400	it 000	loss 3.397e-06	ex 8000	time 8.36s
train	ep 08500	it 000	loss 4.720e-06	ex 8000	time 7.41s
train	ep 08600	it 000	loss 1.441e-06	ex 8000	time 7.40s
train	ep 08700	it 000	loss 3.381e-06	ex 8000	time 7.37s
train	ep 08800	it 000	loss 7.360e-06	ex 8000	time 7.15s
train	ep 08900	it 000	loss 5.851e-06	ex 8000	time 7.34s
train	ep 09000	it 000	loss 3.004e-06	ex 8000	time 7.65s
train	ep 09100	it 000	loss 1.635e-05	ex 8000	time 8.03s
train	ep 09200	it 000	loss 9.630e-07	ex 8000	time 8.08s
train	ep 09300	it 000	loss 3.351e-06	ex 8000	time 7.47s
train	ep 09400	it 000	loss 5.344e-06	ex 8000	time 7.16s
train	ep 09500	it 000	loss 1.092e-06	ex 8000	time 7.16s
train	ep 09600	it 000	loss 2.885e-06	ex 8000	time 7.33s
train	ep 09700	it 000	loss 5.619e-06	ex 8000	time 8.06s
train	ep 09800	it 000	loss 9.952e-06	ex 8000	time 7.12s
train	ep 09900	it 000	loss 5.955e-06	ex 8000	time 7.30s
train	ep 10000	it 000	loss 1.766e-06	ex 8000	time 7.16s
============================================================================================================================================
Reconstruction
--------------------------------------------------------------------------------------------------------------------------------------------
Reconstruction Location: /home/alvin/expand-and-cluster/data/sims/ec_d2cbdbf017/seed_-1/main/clustering_995dc42cbd
--------------------------------------------------------------------------------------------------------------------------------------------

Generating dataset with teacher...
--------------------------------------------------------------------------------------------------------------------------------------------
Layer 0
--------------------------------------------------------------------------------------------------------------------------------------------

computing pairwise L2 distances... Done!
Finding tree cut threshold
Extracting clusters
Found 6 of size bigger than 16.0.
removing 2/6 unaligned clusters
Collapsing 4 clusters.
producing dendrogram...
producing simmat...
Collapsing based on best student neuron 'cluster number -> student rank':
#0->1, #1->1, #2->1, #3->2,
Final layer size: 4

MSE of linear component after reconstruction 0.19136643787522833
Traceback (most recent call last):
  File "/home/alvin/expand-and-cluster/EC.py", line 76, in <module>
    main()
  File "/home/alvin/expand-and-cluster/EC.py", line 72, in main
    platform.run_job(runner_registry.get(runner_name).create_from_args(args).run)
  File "/home/alvin/expand-and-cluster/platforms/base.py", line 130, in run_job
    f()
  File "/home/alvin/expand-and-cluster/extraction/runner.py", line 79, in run
    expand_and_cluster.reconstruct(students, losses, self.desc.extraction_path(self.global_seed),
  File "/home/alvin/expand-and-cluster/extraction/expand_and_cluster.py", line 237, in reconstruct
    teacher_comparison(teacher, students, symmetry, cluster_mask, alignment_reconstruction)
  File "/home/alvin/expand-and-cluster/extraction/expand_and_cluster.py", line 327, in teacher_comparison
    out = compare_with_teacher(wt, bt, at, ws, bs, as_, symmetry, cluster_mask=cluster_mask, verbose=True)
  File "/home/alvin/expand-and-cluster/extraction/layer_reconstruction.py", line 398, in compare_with_teacher
    idx_sorted = np.argsort(np.linalg.norm(at, ord=2, axis=1))[::-1]
  File "/home/alvin/expand-and-cluster/venv/lib/python3.10/site-packages/numpy/linalg/linalg.py", line 2583, in norm
    return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1
