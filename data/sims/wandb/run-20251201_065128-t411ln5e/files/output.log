Generating dataset with teacher...
============================================================================================================================================
Reconstruction
--------------------------------------------------------------------------------------------------------------------------------------------
Reconstruction Location: /root/expand_and_cluster/data/sims/ec_3c2502264b/seed_-1/main/clustering_be50247864
--------------------------------------------------------------------------------------------------------------------------------------------

Generating dataset with teacher...
--------------------------------------------------------------------------------------------------------------------------------------------
Layer 0
--------------------------------------------------------------------------------------------------------------------------------------------

computing pairwise L2 distances... Done!
Finding tree cut threshold
Extracting clusters
Found 30 of size bigger than 2.9.
removing 0/30 unaligned clusters
Collapsing 30 clusters.
producing dendrogram...
producing simmat...
Collapsing based on best student neuron 'cluster number -> student rank':
#0->1, #3->3, #6->1, #10->5, #11->2, #12->3, #14->1, #15->1, #16->1, #17->1, #19->4, #22->1, #23->1, #25->2, #29->3,
Final layer size: 15

train	ep 00000	it 000	loss 1.559e+01	ex 10000	time 0.00s
Traceback (most recent call last):
  File "/root/expand_and_cluster/EC.py", line 76, in <module>
    main()
  File "/root/expand_and_cluster/EC.py", line 72, in main
    platform.run_job(runner_registry.get(runner_name).create_from_args(args).run)
  File "/root/expand_and_cluster/platforms/base.py", line 130, in run_job
    f()
  File "/root/expand_and_cluster/extraction/runner.py", line 79, in run
    expand_and_cluster.reconstruct(students, losses, self.desc.extraction_path(self.global_seed),
  File "/root/expand_and_cluster/extraction/expand_and_cluster.py", line 191, in reconstruct
    train(finetune_hparams, students, train_loader,
  File "/root/expand_and_cluster/training/train.py", line 126, in train
    for it, (examples, labels) in enumerate(train_loader):
  File "/opt/miniconda3/envs/ec_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/opt/miniconda3/envs/ec_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/opt/miniconda3/envs/ec_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/opt/miniconda3/envs/ec_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
KeyboardInterrupt
