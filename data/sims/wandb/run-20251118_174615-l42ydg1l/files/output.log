Generating dataset with teacher...
train	ep 00000	it 000	loss 1.563e+01	ex 8000	time 0.00s
train	ep 00100	it 000	loss 1.182e-02	ex 8000	time 6.32s
train	ep 00200	it 000	loss 4.446e-03	ex 8000	time 5.68s
train	ep 00300	it 000	loss 2.586e-03	ex 8000	time 5.78s
train	ep 00400	it 000	loss 1.876e-03	ex 8000	time 5.87s
train	ep 00500	it 000	loss 1.533e-03	ex 8000	time 5.94s
train	ep 00600	it 000	loss 1.325e-03	ex 8000	time 6.69s
train	ep 00700	it 000	loss 1.066e-03	ex 8000	time 7.35s
train	ep 00800	it 000	loss 9.070e-04	ex 8000	time 7.21s
train	ep 00900	it 000	loss 8.349e-04	ex 8000	time 6.54s
train	ep 01000	it 000	loss 7.578e-04	ex 8000	time 6.62s
train	ep 01100	it 000	loss 7.852e-04	ex 8000	time 6.46s
train	ep 01200	it 000	loss 7.279e-04	ex 8000	time 6.86s
train	ep 01300	it 000	loss 6.358e-04	ex 8000	time 6.62s
train	ep 01400	it 000	loss 6.186e-04	ex 8000	time 7.08s
train	ep 01500	it 000	loss 6.245e-04	ex 8000	time 6.43s
train	ep 01600	it 000	loss 6.067e-04	ex 8000	time 6.66s
train	ep 01700	it 000	loss 6.035e-04	ex 8000	time 6.35s
train	ep 01800	it 000	loss 5.891e-04	ex 8000	time 7.38s
train	ep 01900	it 000	loss 6.027e-04	ex 8000	time 7.58s
train	ep 02000	it 000	loss 4.939e-04	ex 8000	time 7.34s
train	ep 02100	it 000	loss 4.821e-04	ex 8000	time 8.34s
train	ep 02200	it 000	loss 5.180e-04	ex 8000	time 7.48s
train	ep 02300	it 000	loss 4.901e-04	ex 8000	time 6.80s
train	ep 02400	it 000	loss 4.954e-04	ex 8000	time 6.63s
train	ep 02500	it 000	loss 4.813e-04	ex 8000	time 7.00s
train	ep 02600	it 000	loss 4.837e-04	ex 8000	time 7.03s
train	ep 02700	it 000	loss 4.693e-04	ex 8000	time 7.09s
train	ep 02800	it 000	loss 4.762e-04	ex 8000	time 6.33s
train	ep 02900	it 000	loss 4.662e-04	ex 8000	time 6.58s
train	ep 03000	it 000	loss 4.947e-04	ex 8000	time 6.50s
train	ep 03100	it 000	loss 4.615e-04	ex 8000	time 6.68s
train	ep 03200	it 000	loss 4.627e-04	ex 8000	time 6.19s
train	ep 03300	it 000	loss 4.321e-04	ex 8000	time 6.36s
train	ep 03400	it 000	loss 4.264e-04	ex 8000	time 6.96s
train	ep 03500	it 000	loss 4.504e-04	ex 8000	time 7.50s
train	ep 03600	it 000	loss 3.964e-04	ex 8000	time 7.25s
train	ep 03700	it 000	loss 4.191e-04	ex 8000	time 8.24s
train	ep 03800	it 000	loss 3.422e-04	ex 8000	time 6.56s
train	ep 03900	it 000	loss 3.474e-04	ex 8000	time 6.25s
train	ep 04000	it 000	loss 3.481e-04	ex 8000	time 6.63s
train	ep 04100	it 000	loss 3.371e-04	ex 8000	time 6.63s
train	ep 04200	it 000	loss 3.521e-04	ex 8000	time 6.49s
train	ep 04300	it 000	loss 3.772e-04	ex 8000	time 6.76s
train	ep 04400	it 000	loss 3.300e-04	ex 8000	time 6.93s
train	ep 04500	it 000	loss 3.376e-04	ex 8000	time 6.07s
train	ep 04600	it 000	loss 3.350e-04	ex 8000	time 6.07s
train	ep 04700	it 000	loss 3.447e-04	ex 8000	time 6.59s
train	ep 04800	it 000	loss 3.529e-04	ex 8000	time 7.71s
train	ep 04900	it 000	loss 3.355e-04	ex 8000	time 7.80s
train	ep 05000	it 000	loss 3.243e-04	ex 8000	time 6.20s
train	ep 05100	it 000	loss 2.902e-04	ex 8000	time 6.07s
train	ep 05200	it 000	loss 2.870e-04	ex 8000	time 6.11s
train	ep 05300	it 000	loss 2.854e-04	ex 8000	time 7.76s
train	ep 05400	it 000	loss 2.735e-04	ex 8000	time 8.43s
train	ep 05500	it 000	loss 2.699e-04	ex 8000	time 9.88s
train	ep 05600	it 000	loss 2.648e-04	ex 8000	time 8.60s
train	ep 05700	it 000	loss 2.611e-04	ex 8000	time 7.54s
train	ep 05800	it 000	loss 2.920e-04	ex 8000	time 7.30s
train	ep 05900	it 000	loss 2.631e-04	ex 8000	time 6.79s
train	ep 06000	it 000	loss 2.525e-04	ex 8000	time 7.90s
train	ep 06100	it 000	loss 2.482e-04	ex 8000	time 7.44s
train	ep 06200	it 000	loss 3.090e-04	ex 8000	time 7.28s
train	ep 06300	it 000	loss 2.664e-04	ex 8000	time 7.01s
train	ep 06400	it 000	loss 2.569e-04	ex 8000	time 6.55s
train	ep 06500	it 000	loss 2.582e-04	ex 8000	time 8.15s
train	ep 06600	it 000	loss 2.718e-04	ex 8000	time 7.83s
train	ep 06700	it 000	loss 2.553e-04	ex 8000	time 7.30s
train	ep 06800	it 000	loss 2.505e-04	ex 8000	time 6.68s
train	ep 06900	it 000	loss 2.730e-04	ex 8000	time 7.08s
train	ep 07000	it 000	loss 2.528e-04	ex 8000	time 7.53s
train	ep 07100	it 000	loss 2.505e-04	ex 8000	time 7.24s
train	ep 07200	it 000	loss 2.464e-04	ex 8000	time 7.35s
train	ep 07300	it 000	loss 2.832e-04	ex 8000	time 7.81s
train	ep 07400	it 000	loss 2.725e-04	ex 8000	time 8.32s
train	ep 07500	it 000	loss 2.610e-04	ex 8000	time 7.60s
train	ep 07600	it 000	loss 2.872e-04	ex 8000	time 8.35s
train	ep 07700	it 000	loss 2.495e-04	ex 8000	time 6.93s
train	ep 07800	it 000	loss 2.389e-04	ex 8000	time 6.98s
train	ep 07900	it 000	loss 2.641e-04	ex 8000	time 7.01s
train	ep 08000	it 000	loss 2.438e-04	ex 8000	time 7.21s
train	ep 08100	it 000	loss 2.399e-04	ex 8000	time 6.57s
train	ep 08200	it 000	loss 2.594e-04	ex 8000	time 6.29s
train	ep 08300	it 000	loss 2.508e-04	ex 8000	time 7.53s
train	ep 08400	it 000	loss 2.446e-04	ex 8000	time 7.33s
train	ep 08500	it 000	loss 2.489e-04	ex 8000	time 6.93s
train	ep 08600	it 000	loss 2.337e-04	ex 8000	time 7.17s
train	ep 08700	it 000	loss 2.455e-04	ex 8000	time 6.94s
train	ep 08800	it 000	loss 2.789e-04	ex 8000	time 6.39s
train	ep 08900	it 000	loss 2.519e-04	ex 8000	time 7.44s
train	ep 09000	it 000	loss 2.318e-04	ex 8000	time 7.12s
train	ep 09100	it 000	loss 2.538e-04	ex 8000	time 7.17s
train	ep 09200	it 000	loss 2.315e-04	ex 8000	time 7.06s
train	ep 09300	it 000	loss 2.279e-04	ex 8000	time 7.19s
train	ep 09400	it 000	loss 2.566e-04	ex 8000	time 6.76s
train	ep 09500	it 000	loss 2.424e-04	ex 8000	time 7.33s
train	ep 09600	it 000	loss 2.699e-04	ex 8000	time 6.86s
train	ep 09700	it 000	loss 2.376e-04	ex 8000	time 7.38s
train	ep 09800	it 000	loss 2.312e-04	ex 8000	time 7.09s
train	ep 09900	it 000	loss 2.455e-04	ex 8000	time 7.55s
train	ep 10000	it 000	loss 2.317e-04	ex 8000	time 7.33s
============================================================================================================================================
Reconstruction
--------------------------------------------------------------------------------------------------------------------------------------------
Reconstruction Location: /home/alvin/expand-and-cluster/data/sims/ec_cadfbeebfd/seed_-1/main/clustering_a48fe7727a
--------------------------------------------------------------------------------------------------------------------------------------------

Generating dataset with teacher...
--------------------------------------------------------------------------------------------------------------------------------------------
Layer 0
--------------------------------------------------------------------------------------------------------------------------------------------

computing pairwise L2 distances... Done!
Finding tree cut threshold
Extracting clusters
Found 8 of size bigger than 8.0.
removing 0/8 unaligned clusters
Collapsing 8 clusters.
producing dendrogram...
producing simmat...
Collapsing based on best student neuron 'cluster number -> student rank':
#0->1, #1->1, #2->3, #3->1, #4->1, #5->2, #6->1, #7->1,
Final layer size: 8

train	ep 00000	it 000	loss 1.865e+01	ex 8000	time 0.00s
train	ep 00100	it 000	loss 1.461e+00	ex 8000	time 8.86s
train	ep 00200	it 000	loss 2.743e-01	ex 8000	time 8.57s
train	ep 00300	it 000	loss 1.056e-01	ex 8000	time 8.54s
train	ep 00400	it 000	loss 4.788e-02	ex 8000	time 8.50s
train	ep 00500	it 000	loss 2.621e-02	ex 8000	time 8.54s
train	ep 00600	it 000	loss 1.550e-02	ex 8000	time 8.59s
train	ep 00700	it 000	loss 9.215e-03	ex 8000	time 8.75s
train	ep 00800	it 000	loss 6.271e-03	ex 8000	time 8.33s
train	ep 00900	it 000	loss 4.896e-03	ex 8000	time 8.24s
train	ep 01000	it 000	loss 4.125e-03	ex 8000	time 8.56s
train	ep 01100	it 000	loss 3.639e-03	ex 8000	time 9.00s
train	ep 01200	it 000	loss 3.346e-03	ex 8000	time 8.83s
train	ep 01300	it 000	loss 3.144e-03	ex 8000	time 8.14s
train	ep 01400	it 000	loss 3.005e-03	ex 8000	time 8.08s
train	ep 01500	it 000	loss 2.903e-03	ex 8000	time 8.07s
train	ep 01600	it 000	loss 2.823e-03	ex 8000	time 8.33s
train	ep 01700	it 000	loss 2.719e-03	ex 8000	time 8.33s
train	ep 01800	it 000	loss 2.641e-03	ex 8000	time 8.33s
train	ep 01900	it 000	loss 2.565e-03	ex 8000	time 8.22s
train	ep 02000	it 000	loss 2.501e-03	ex 8000	time 8.26s
train	ep 02100	it 000	loss 2.442e-03	ex 8000	time 8.40s
train	ep 02200	it 000	loss 2.380e-03	ex 8000	time 8.39s
train	ep 02300	it 000	loss 2.353e-03	ex 8000	time 8.32s
train	ep 02400	it 000	loss 2.312e-03	ex 8000	time 8.34s
train	ep 02500	it 000	loss 2.277e-03	ex 8000	time 8.26s
train	ep 02600	it 000	loss 2.248e-03	ex 8000	time 8.19s
train	ep 02700	it 000	loss 2.220e-03	ex 8000	time 8.00s
train	ep 02800	it 000	loss 2.193e-03	ex 8000	time 7.98s
train	ep 02900	it 000	loss 2.182e-03	ex 8000	time 8.05s
train	ep 03000	it 000	loss 2.168e-03	ex 8000	time 8.00s
train	ep 03100	it 000	loss 2.112e-03	ex 8000	time 8.08s
train	ep 03200	it 000	loss 2.087e-03	ex 8000	time 8.11s
train	ep 03300	it 000	loss 2.062e-03	ex 8000	time 8.10s
train	ep 03400	it 000	loss 2.045e-03	ex 8000	time 8.29s
train	ep 03500	it 000	loss 2.026e-03	ex 8000	time 9.39s
train	ep 03600	it 000	loss 2.005e-03	ex 8000	time 8.83s
train	ep 03700	it 000	loss 1.990e-03	ex 8000	time 8.54s
train	ep 03800	it 000	loss 1.969e-03	ex 8000	time 8.18s
train	ep 03900	it 000	loss 1.962e-03	ex 8000	time 8.17s
train	ep 04000	it 000	loss 1.940e-03	ex 8000	time 8.18s
train	ep 04100	it 000	loss 1.931e-03	ex 8000	time 8.14s
train	ep 04200	it 000	loss 1.916e-03	ex 8000	time 7.90s
train	ep 04300	it 000	loss 1.895e-03	ex 8000	time 8.30s
train	ep 04400	it 000	loss 1.881e-03	ex 8000	time 7.92s
train	ep 04500	it 000	loss 1.872e-03	ex 8000	time 7.95s
train	ep 04600	it 000	loss 1.871e-03	ex 8000	time 8.06s
train	ep 04700	it 000	loss 1.852e-03	ex 8000	time 8.40s
train	ep 04800	it 000	loss 1.856e-03	ex 8000	time 8.08s
train	ep 04900	it 000	loss 1.810e-03	ex 8000	time 8.01s
train	ep 05000	it 000	loss 1.771e-03	ex 8000	time 7.96s
--------------------------------------------------------------------------------------------------------------------------------------------
Layer 1
--------------------------------------------------------------------------------------------------------------------------------------------

computing pairwise L2 distances... Done!
Finding tree cut threshold
Extracting clusters
Found 15 of size bigger than 8.0.
removing 15/15 unaligned clusters
Collapsing 0 clusters.
producing dendrogram...
producing simmat...
Collapsing based on best student neuron 'cluster number -> student rank':

Final layer size: 0
Traceback (most recent call last):
  File "/home/alvin/expand-and-cluster/EC.py", line 76, in <module>
    main()
  File "/home/alvin/expand-and-cluster/EC.py", line 72, in main
    platform.run_job(runner_registry.get(runner_name).create_from_args(args).run)
  File "/home/alvin/expand-and-cluster/platforms/base.py", line 130, in run_job
    f()
  File "/home/alvin/expand-and-cluster/extraction/runner.py", line 79, in run
    expand_and_cluster.reconstruct(students, losses, self.desc.extraction_path(self.global_seed),
  File "/home/alvin/expand-and-cluster/extraction/expand_and_cluster.py", line 175, in reconstruct
    w_rec = np.stack([w_rec]*N, axis=2)
  File "/home/alvin/expand-and-cluster/venv/lib/python3.10/site-packages/numpy/core/shape_base.py", line 452, in stack
    axis = normalize_axis_index(axis, result_ndim)
numpy.exceptions.AxisError: axis 2 is out of bounds for array of dimension 2
